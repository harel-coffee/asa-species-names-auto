{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#select GPU to run script\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#create the combined model VGG FNN#\n",
    "###################################\n",
    "\n",
    "def MLP_CNN():\n",
    "    #Input: [Image matrix (shape = (n, y, x, num_channels), Centroid matrix (shape = (n, 2))]\n",
    "    #E.g.: [I_train, C_train]\n",
    "    #Y (Y_train) is of shape (n, n_classes)\n",
    "    \n",
    "    input1 = keras.layers.Input(shape=(y_image, x_image, num_channels),name = 'image_input')\n",
    "\n",
    "    vgg_output =  vgg_conv(input1)\n",
    "\n",
    "    for layer in vgg_conv.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    for layer in vgg_conv.layers:\n",
    "        print(layer, layer.trainable)\n",
    "\n",
    "    x1 = keras.layers.Flatten()(vgg_output)\n",
    "    x1 = keras.layers.Dense(1024, activation='relu', name='dense_1')(x1)\n",
    "    x1 = keras.layers.Dropout(0.5, name='dropout')(x1)\n",
    "\n",
    "    input2 = keras.layers.Input(shape=(2,), name='coordinate_input')\n",
    "    x2 = keras.layers.Dense(4, activation='relu', name='dense_2')(input2)\n",
    "\n",
    "    merged = keras.layers.merge([x1, x2], mode='concat')\n",
    "    out = keras.layers.Dense(n_classes, activation='sigmoid', name='output')(merged)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MLP_CNN_BLSTM():\n",
    "    #Input: [Image matrix (shape = (n, seq_len, y, x, num_channels), Centroid matrix (shape = (n, seq_len, 2))]\n",
    "    #E.g.: [I_train, C_train]\n",
    "    #Y (Y_train) is of shape (n, seq_len, n_classes)\n",
    "    \n",
    "    input_cnn = keras.layers.Input(shape=(y_image, x_image, num_channels),name = 'image_input')\n",
    "\n",
    "    vgg_output =  vgg_conv(input_cnn)\n",
    "\n",
    "    for layer in vgg_conv.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    for layer in vgg_conv.layers:\n",
    "        print(layer, layer.trainable)\n",
    "\n",
    "    x1 = keras.layers.Flatten()(vgg_output)\n",
    "    x1 = keras.layers.Dense(1024, activation='relu', name='dense_1')(x1)\n",
    "    x1 = keras.layers.Dropout(0.5, name='dropout')(x1)\n",
    "    \n",
    "    input_ffnn = keras.layers.Input(shape=(2,), name='coordinate_input')\n",
    "    x2 = keras.layers.Dense(4, activation='relu', name='dense_2')(input_ffnn)\n",
    "\n",
    "    ffnn = keras.models.Model(inputs=input_ffnn, outputs=x2)\n",
    "    cnn = keras.models.Model(inputs=input_cnn, outputs=x1)\n",
    "\n",
    "    I_sequence = keras.layers.Input(shape=(None, y_image, x_image, num_channels))\n",
    "    X_sequence = keras.layers.Input(shape=(None, 2))\n",
    "\n",
    "    time_x1 = keras.layers.TimeDistributed(ffnn)(X_sequence)\n",
    "    time_x2 = keras.layers.TimeDistributed(cnn)(I_sequence)\n",
    "\n",
    "    merged = keras.layers.merge([time_x1, time_x2], mode='concat')\n",
    "    \n",
    "    seq_dat = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(merged)\n",
    "\n",
    "    hidden = keras.layers.Dense(output_dim=1024, activation=\"relu\")(seq_dat)\n",
    "    outputs = keras.layers.Dense(output_dim=n_classes, activation=\"softmax\")(hidden)\n",
    "    \n",
    "    model = keras.models.Model([I_sequence,X_sequence], outputs=outputs)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
