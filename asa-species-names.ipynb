{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#select GPU to run script\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#Read in sequence data#\n",
    "#######################\n",
    "\n",
    "df1 = pd.read_pickle('../data/seq_data1.pkl') \n",
    "df2 = pd.read_pickle('../data/seq_data2.pkl')\n",
    "df3 = pd.read_pickle('../data/seq_data3.pkl')\n",
    "df4 = pd.read_pickle('../data/seq_data4.pkl')\n",
    "\n",
    "df_seq = pd.concat([df1, df2, df3,df4]) #sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the dataset:<br>\n",
    "\n",
    "<b>Y1</b> = multiclass label for first image of sequence<br>\n",
    "<b>Y2</b> = multiclass label for second image of sequence<br>\n",
    "\n",
    "<b>centroid1</b> = [x,y] of centroid for first image of sequence<br>\n",
    "<b>centroid2</b> = [x,y] of centroid for second image of sequence\n",
    "\n",
    "<b>idx1</b> = unique identifier for first image of sequence (index of dataframe with singular images rather than sequences)<br>\n",
    "<b>idx2</b> = unique identifier for second image of sequence (index of dataframe with singular images rather than sequences)\n",
    "\n",
    "<b>image1</b> = pixel values for first image of sequence. shape=(height,width,num_channels)<br>\n",
    "<b>image2</b> = pixel values for second image of sequence. shape=(height,width,num_channels)\n",
    "\n",
    "<b>page1</b> = page from which first image of sequence originates<br>\n",
    "<b>page2</b> = page from which second image of sequence originates (should be identical to page1)\n",
    "\n",
    "<b>roi1</b> = [x1,x2,y1,y2] of the first image of the sequence, relative to the full image<br>\n",
    "<b>roi2</b> = [x1,x2,y1,y2] of the second image of the sequence, relative to the full image\n",
    "\n",
    "<b>y1</b> = 1dim label for first image of sequence <br>\n",
    "<b>y2</b> = 2dim label for second image of sequence\n",
    "\n",
    "<font color='red'>Note that most images have duplicates!! They appear in one sequence but also in another! E.g. Genus-species species-author. Therefore, they have unique identifiers. They should not be in the test-set as well as in the train set! Furthermore, don't count them twice when evaluating the model!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#create the combined model VGG FNN#\n",
    "###################################\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "\n",
    "def MLP_CNN():\n",
    "    #Input: [Image matrix (shape = (n, y, x, num_channels), Centroid matrix (shape = (n, 2))]\n",
    "    #E.g.: [I_train, C_train]\n",
    "    #Y (Y_train) is of shape (n, n_classes)\n",
    "    \n",
    "    input1 = keras.layers.Input(shape=(y_image, x_image, num_channels),name = 'image_input')\n",
    "\n",
    "    vgg_output =  vgg_conv(input1)\n",
    "\n",
    "    for layer in vgg_conv.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    for layer in vgg_conv.layers:\n",
    "        print(layer, layer.trainable)\n",
    "\n",
    "    x1 = keras.layers.Flatten()(vgg_output)\n",
    "    x1 = keras.layers.Dense(1024, activation='relu', name='dense_1')(x1)\n",
    "    x1 = keras.layers.Dropout(0.5, name='dropout')(x1)\n",
    "\n",
    "    input2 = keras.layers.Input(shape=(2,), name='coordinate_input')\n",
    "    x2 = keras.layers.Dense(4, activation='relu', name='dense_2')(input2)\n",
    "\n",
    "    merged = keras.layers.merge([x1, x2], mode='concat')\n",
    "    out = keras.layers.Dense(n_classes, activation='sigmoid', name='output')(merged)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_CNN_BLSTM():\n",
    "    #Input: [Image matrix (shape = (n, seq_len, y, x, num_channels), Centroid matrix (shape = (n, seq_len, 2))]\n",
    "    #E.g.: [I_train, C_train]\n",
    "    #Y (Y_train) is of shape (n, seq_len, n_classes)\n",
    "    \n",
    "    input_cnn = keras.layers.Input(shape=(y_image, x_image, num_channels),name = 'image_input')\n",
    "\n",
    "    vgg_output =  vgg_conv(input_cnn)\n",
    "\n",
    "    for layer in vgg_conv.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    for layer in vgg_conv.layers:\n",
    "        print(layer, layer.trainable)\n",
    "\n",
    "    x1 = keras.layers.Flatten()(vgg_output)\n",
    "    x1 = keras.layers.Dense(1024, activation='relu', name='dense_1')(x1)\n",
    "    x1 = keras.layers.Dropout(0.5, name='dropout')(x1)\n",
    "    \n",
    "    input_ffnn = keras.layers.Input(shape=(2,), name='coordinate_input')\n",
    "    x2 = keras.layers.Dense(4, activation='relu', name='dense_2')(input_ffnn)\n",
    "\n",
    "    ffnn = keras.models.Model(inputs=input_ffnn, outputs=x2)\n",
    "    cnn = keras.models.Model(inputs=input_cnn, outputs=x1)\n",
    "\n",
    "    I_sequence = keras.layers.Input(shape=(None, y_image, x_image, num_channels))\n",
    "    X_sequence = keras.layers.Input(shape=(None, 2))\n",
    "\n",
    "    time_x1 = keras.layers.TimeDistributed(ffnn)(X_sequence)\n",
    "    time_x2 = keras.layers.TimeDistributed(cnn)(I_sequence)\n",
    "\n",
    "    merged = keras.layers.merge([time_x1, time_x2], mode='concat')\n",
    "    \n",
    "    seq_dat = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(merged)\n",
    "\n",
    "    hidden = keras.layers.Dense(output_dim=1024, activation=\"relu\")(seq_dat)\n",
    "    outputs = keras.layers.Dense(output_dim=n_classes, activation=\"softmax\")(hidden)\n",
    "    \n",
    "    model = keras.models.Model([I_sequence,X_sequence], outputs=outputs)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order word images per page, shuffle pages. \n",
    "df_page = df_seq.set_index(['page1',df_seq.index])\n",
    "shuffled = np.random.RandomState(seed=42).permutation(np.unique(df_page.index.get_level_values(level=0)))\n",
    "df_shuff = pd.concat([df_page.loc[i:i] for i in shuffled])\n",
    "\n",
    "#create a mask for 20% of the data\n",
    "split = math.ceil(len(df_shuff)*0.2)\n",
    "df_shuff['idx'] = df_shuff.reset_index().index\n",
    "mask = df_shuff['idx'].isin(list(np.arange(0,split)))\n",
    "\n",
    "#create a test and train set\n",
    "test = df_shuff.loc[mask]\n",
    "train = df_shuff.loc[~mask] \n",
    "\n",
    "#get test and train data\n",
    "I_test = np.array([[x for x in i] for i in test[['image1','image2']].values], dtype=np.float16)\n",
    "I_train = np.array([[x for x in i] for i in train[['image1','image2']].values], dtype=np.float16)\n",
    "\n",
    "C_test = np.array([[x for x in i] for i in test[['centroid1','centroid2']].values], dtype=np.float16)\n",
    "C_train = np.array([[x for x in i] for i in train[['centroid1','centroid2']].values], dtype=np.float16)\n",
    "\n",
    "Y_test = np.array([[x for x in i] for i in test[['Y1','Y2']].values], dtype=np.float16)\n",
    "Y_train = np.array([[x for x in i] for i in train[['Y1','Y2']].values], dtype=np.float16)\n",
    "\n",
    "y_test = np.array([[x for x in i] for i in test[['y1','y2']].values], dtype=np.float16)\n",
    "y_train = np.array([[x for x in i] for i in train[['y1','y2']].values], dtype=np.float16)\n",
    "\n",
    "idx_test = np.array([[x for x in i] for i in test[['idx1','idx2']].values]).reshape(-1)\n",
    "idx_train = np.array([[x for x in i] for i in train[['idx1','idx2']].values]).reshape(-1)\n",
    "\n",
    "(n_test, seq_len, y_image, x_image, num_channels), c_dim, n_train, n_classes, batch_size  = I_test.shape, C_train.shape[-1], I_train.shape[0], Y_train.shape[2], 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#Train MLP_CNN() model on fold#\n",
    "###############################\n",
    "model_path = '../models/MLP_CNN.h5'\n",
    "\n",
    "model = MLP_CNN()\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=0), \n",
    "                 keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit([I_train.reshape(-1, y_image, x_image, num_channels),\n",
    "                    C_train.reshape(-1, c_dim)], \n",
    "                    Y_train.reshape(-1, n_classes),\n",
    "                    validation_data=([I_test.reshape(-1, y_image, x_image, num_channels), \n",
    "                                       C_test.reshape(-1, c_dim)], \n",
    "                                       Y_test.reshape(-1, n_classes)),\n",
    "                    epochs=10, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True, \n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=1)\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "scores = model.evaluate([I_test.reshape(-1, y_image, x_image, num_channels), \n",
    "                        C_test.reshape(-1, c_dim)],\n",
    "                        Y_test.reshape(-1, n_classes))\n",
    "\n",
    "y_pred = model.predict([I_test.reshape(-1, y_image, x_image, num_channels), \n",
    "                        C_test.reshape(-1, c_dim)], verbose=1) \n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print('\\n')\n",
    "print(classification_report(y_test.ravel()[np.unique(idx_test,True)[1]], y_pred.ravel()[np.unique(idx_test,True)[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order word images per page, shuffle pages. \n",
    "df_page = df_seq.set_index(['page1',df_seq.index])\n",
    "shuffled = np.random.RandomState(seed=42).permutation(np.unique(df_page.index.get_level_values(level=0)))\n",
    "df_shuff = pd.concat([df_page.loc[i:i] for i in shuffled])\n",
    "\n",
    "\n",
    "model_path = '../models/MLP_CNN_BLSTM.h5'\n",
    "\n",
    "model = MLP_CNN_BLSTM()\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=0), \n",
    "                 keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit([I_train,C_train],Y_train,\n",
    "                    validation_data=([I_test, C_test], Y_test),\n",
    "                    epochs=10, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True, \n",
    "                    callbacks=callbacks_list, \n",
    "                    verbose=1)\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "scores = model.evaluate([I_test, C_test], Y_test)\n",
    "\n",
    "Y_pred = model.predict([I_test, C_test], verbose=1)\n",
    "\n",
    "y_pred = []\n",
    "for idx, pred in enumerate(Y_pred):\n",
    "    y_pred.append(np.argmax(pred,axis=1))\n",
    "y_pred = np.array(y_pred).reshape(-1,2,1) \n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print('\\n')\n",
    "print(classification_report(y_test.ravel()[np.unique(idx_test,True)[1]], y_pred.ravel()[np.unique(idx_test,True)[1]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
